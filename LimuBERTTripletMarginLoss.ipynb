{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"https://github.com/KevinMusgrave/pytorch-metric-learning/blob/master/examples/notebooks/TripletMarginLossMNIST.ipynb","timestamp":1668702325861}]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lMde13VLDjiH","outputId":"f121c713-fcfd-45cf-f315-1f1010bcc887","executionInfo":{"status":"ok","timestamp":1668707375751,"user_tz":-330,"elapsed":16205,"user":{"displayName":"Nihal Rao","userId":"16198834853640975474"}}},"source":["!pip install pytorch-metric-learning\n","!pip install faiss-gpu"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pytorch-metric-learning\n","  Downloading pytorch_metric_learning-1.6.3-py3-none-any.whl (111 kB)\n","\u001b[K     |████████████████████████████████| 111 kB 14.8 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-metric-learning) (4.64.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pytorch-metric-learning) (1.0.2)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from pytorch-metric-learning) (0.13.1+cu113)\n","Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-metric-learning) (1.12.1+cu113)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-metric-learning) (1.21.6)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (4.1.1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pytorch-metric-learning) (1.2.0)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pytorch-metric-learning) (1.7.3)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pytorch-metric-learning) (3.1.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->pytorch-metric-learning) (7.1.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision->pytorch-metric-learning) (2.23.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->pytorch-metric-learning) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->pytorch-metric-learning) (2022.9.24)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->pytorch-metric-learning) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->pytorch-metric-learning) (3.0.4)\n","Installing collected packages: pytorch-metric-learning\n","Successfully installed pytorch-metric-learning-1.6.3\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting faiss-gpu\n","  Downloading faiss_gpu-1.7.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n","\u001b[K     |████████████████████████████████| 85.5 MB 141 kB/s \n","\u001b[?25hInstalling collected packages: faiss-gpu\n","Successfully installed faiss-gpu-1.7.2\n"]}]},{"cell_type":"code","metadata":{"id":"GJ_L0TrTDnEA","executionInfo":{"status":"ok","timestamp":1668707386197,"user_tz":-330,"elapsed":2274,"user":{"displayName":"Nihal Rao","userId":"16198834853640975474"}}},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","### MNIST code originally from https://github.com/pytorch/examples/blob/master/mnist/main.py ###\n","from torchvision import datasets, transforms\n","\n","from pytorch_metric_learning import distances, losses, miners, reducers, testers\n","from pytorch_metric_learning.utils.accuracy_calculator import AccuracyCalculator\n","\n","\n","### MNIST code originally from https://github.com/pytorch/examples/blob/master/mnist/main.py ###\n","class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.ln = nn.Linear(8640, 128) #should change\n","\n","    def forward(self, x):\n","        x = self.ln(x)\n","        return x\n","\n","\n","### MNIST code originally from https://github.com/pytorch/examples/blob/master/mnist/main.py ###\n","def train(model, loss_func, mining_func, device, train_loader, optimizer, epoch):\n","    model.train()\n","    for batch_idx, (data, labels) in enumerate(train_loader):\n","        data, labels = data.to(device), labels.to(device)\n","        optimizer.zero_grad()\n","        embeddings = model(data)\n","        indices_tuple = mining_func(embeddings, labels)\n","        loss = loss_func(embeddings, labels, indices_tuple)\n","        loss.backward()\n","        optimizer.step()\n","        if batch_idx % 20 == 0:\n","            print(\n","                \"Epoch {} Iteration {}: Loss = {}, Number of mined triplets = {}\".format(\n","                    epoch, batch_idx, loss, mining_func.num_triplets\n","                )\n","            )\n","\n","\n","### convenient function from pytorch-metric-learning ###\n","def get_all_embeddings(dataset, model):\n","    tester = testers.BaseTester()\n","    return tester.get_all_embeddings(dataset, model)\n","\n","\n","### compute accuracy using AccuracyCalculator from pytorch-metric-learning ###\n","def test(train_set, test_set, model, accuracy_calculator):\n","    train_embeddings, train_labels = get_all_embeddings(train_set, model)\n","    test_embeddings, test_labels = get_all_embeddings(test_set, model)\n","    train_labels = train_labels.squeeze(1)\n","    test_labels = test_labels.squeeze(1)\n","    print(\"Computing accuracy\")\n","    accuracies = accuracy_calculator.get_accuracy(\n","        test_embeddings, train_embeddings, test_labels, train_labels, False\n","    )\n","    print(\"Test set accuracy (Precision@1) = {}\".format(accuracies[\"precision_at_1\"]))"],"execution_count":3,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"zQ04Bj_UrcE2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U_C2b5MirerI","executionInfo":{"status":"ok","timestamp":1668706898971,"user_tz":-330,"elapsed":26641,"user":{"displayName":"Nihal Rao","userId":"16198834853640975474"}},"outputId":"c16b5667-c6af-4e48-def0-dc27f3f0eb0d"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import numpy as np\n","with open('/content/drive/MyDrive/uci/walking_labels.npz','rb') as f:\n","  labels = np.load(f)['arr_0']\n","train_mask = labels<=20"],"metadata":{"id":"n_mwbu0nrsYJ","executionInfo":{"status":"ok","timestamp":1668707416802,"user_tz":-330,"elapsed":1137,"user":{"displayName":"Nihal Rao","userId":"16198834853640975474"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["class myDataset(torch.utils.data.Dataset):\n","  def __init__(self, features, labels):\n","        \"\"\"\n","        Args:\n","            csv_file (string): Path to the csv file with annotations.\n","            root_dir (string): Directory with all the images.\n","            transform (callable, optional): Optional transform to be applied\n","                on a sample.\n","        \"\"\"\n","        self.features = features\n","        self.labels = labels\n","\n","  def __len__(self):\n","      return self.labels.shape[0]\n","\n","  def __getitem__(self, idx):\n","      return features[idx], labels[idx]\n","\n","\n","device = torch.device(\"cuda\")\n","\n","batch_size = 16\n","\n"],"metadata":{"id":"iSAA8jFWqm1j","executionInfo":{"status":"ok","timestamp":1668707494110,"user_tz":-330,"elapsed":7,"user":{"displayName":"Nihal Rao","userId":"16198834853640975474"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","features = np.load('/content/drive/MyDrive/uci/walking_data_limu_bert.npz')['arr_0']\n","train_l = labels[train_mask]\n","train_f = features[train_mask]\n","test_l = labels[np.logical_not(train_mask)]\n","test_f = features[np.logical_not(train_mask)]\n","\n","dataset1 = myDataset(train_f, train_l)\n","dataset2 = myDataset(test_f, test_l) #\n","train_loader = torch.utils.data.DataLoader(\n","    dataset1, batch_size=batch_size, shuffle=True\n",")\n","test_loader = torch.utils.data.DataLoader(dataset2, batch_size=batch_size)\n","\n","model = Net().to(device)\n","optimizer = optim.Adam(model.parameters(), lr=0.01)\n","num_epochs = 10"],"metadata":{"id":"x0Mg393Prymn","executionInfo":{"status":"ok","timestamp":1668707931155,"user_tz":-330,"elapsed":13,"user":{"displayName":"Nihal Rao","userId":"16198834853640975474"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["### pytorch-metric-learning stuff ###\n","distance = distances.LpDistance()\n","reducer = reducers.ThresholdReducer(low=0)\n","loss_func = losses.TripletMarginLoss(margin=0.2, distance=distance, reducer=reducer)\n","mining_func = miners.TripletMarginMiner(\n","    margin=0.2, distance=distance, type_of_triplets=\"semihard\"\n",")\n","accuracy_calculator = AccuracyCalculator(include=(\"precision_at_1\",), k=1)\n","### pytorch-metric-learning stuff ###\n","\n","\n","for epoch in range(1, num_epochs + 1):\n","    train(model, loss_func, mining_func, device, train_loader, optimizer, epoch)\n","    test(dataset1, dataset2, model, accuracy_calculator)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xMmpvc77qr06","executionInfo":{"status":"ok","timestamp":1668707940481,"user_tz":-330,"elapsed":5401,"user":{"displayName":"Nihal Rao","userId":"16198834853640975474"}},"outputId":"3f178d4c-050e-4992-971f-5a613107a476"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1 Iteration 0: Loss = 0.10746381431818008, Number of mined triplets = 42\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 8/8 [00:00<00:00, 30.67it/s]\n","100%|██████████| 4/4 [00:00<00:00, 31.69it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Computing accuracy\n","Test set accuracy (Precision@1) = 1.0\n","Epoch 2 Iteration 0: Loss = 0.10504515469074249, Number of mined triplets = 19\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 8/8 [00:00<00:00, 60.40it/s]\n","100%|██████████| 4/4 [00:00<00:00, 34.82it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Computing accuracy\n","Test set accuracy (Precision@1) = 1.0\n","Epoch 3 Iteration 0: Loss = 0.1029612123966217, Number of mined triplets = 23\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 8/8 [00:00<00:00, 62.22it/s]\n","100%|██████████| 4/4 [00:00<00:00, 33.52it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Computing accuracy\n","Test set accuracy (Precision@1) = 1.0\n","Epoch 4 Iteration 0: Loss = 0.10332545638084412, Number of mined triplets = 11\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 8/8 [00:00<00:00, 57.15it/s]\n","100%|██████████| 4/4 [00:00<00:00, 34.81it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Computing accuracy\n","Test set accuracy (Precision@1) = 1.0\n","Epoch 5 Iteration 0: Loss = 0.1115468367934227, Number of mined triplets = 14\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 8/8 [00:00<00:00, 60.81it/s]\n","100%|██████████| 4/4 [00:00<00:00, 33.31it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Computing accuracy\n","Test set accuracy (Precision@1) = 1.0\n","Epoch 6 Iteration 0: Loss = 0.1153821051120758, Number of mined triplets = 18\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 8/8 [00:00<00:00, 60.07it/s]\n","100%|██████████| 4/4 [00:00<00:00, 33.54it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Computing accuracy\n","Test set accuracy (Precision@1) = 1.0\n","Epoch 7 Iteration 0: Loss = 0.13504187762737274, Number of mined triplets = 10\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 8/8 [00:00<00:00, 61.35it/s]\n","100%|██████████| 4/4 [00:00<00:00, 33.02it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Computing accuracy\n","Test set accuracy (Precision@1) = 1.0\n","Epoch 8 Iteration 0: Loss = 0.12508916854858398, Number of mined triplets = 10\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 8/8 [00:00<00:00, 61.59it/s]\n","100%|██████████| 4/4 [00:00<00:00, 31.69it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Computing accuracy\n","Test set accuracy (Precision@1) = 1.0\n","Epoch 9 Iteration 0: Loss = 0.10460007190704346, Number of mined triplets = 18\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 8/8 [00:00<00:00, 64.03it/s]\n","100%|██████████| 4/4 [00:00<00:00, 31.26it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Computing accuracy\n","Test set accuracy (Precision@1) = 1.0\n","Epoch 10 Iteration 0: Loss = 0.0787685364484787, Number of mined triplets = 10\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 8/8 [00:00<00:00, 61.25it/s]\n","100%|██████████| 4/4 [00:00<00:00, 32.88it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Computing accuracy\n","Test set accuracy (Precision@1) = 1.0\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import top_k_accuracy_score\n","\n","model.eval()\n","def eval_emb():\n","  y_pred = []\n","  y_true = []\n","  for i in range(test_l.shape[0]):\n","    trial = []\n","    for j in range(10):\n","      cl=j+21\n","      cl_samples = test_f[test_l==cl]\n","      trial.append(cl_samples[np.random.choice(cl_samples.shape[0])])\n","    x = test_f[i]\n","    # trial = np.concatenate(trial, axis=0)\n","    trial = np.vstack(trial)\n","    trial = np.concatenate((trial, x[None,:]), axis=0)\n","    with torch.no_grad():\n","      embed = model(torch.tensor(trial).to(device))\n","      embed = embed.cpu().numpy()\n","    trial = embed[:-1,:]\n","    x = embed[-1,:]\n","    # print('trual shape is',trial.shape)\n","    scores = -np.mean((trial - x)**2, axis=-1)\n","    # print('scores shape is',scores.shape)\n","    y_pred.append(scores)\n","    y_true.append(test_l[i])\n","  y_true = np.asarray(y_true)\n","  y_pred = np.vstack(y_pred)\n","  # print('y_pred shape', y_pred.shape)\n","  # print('y_true shape', y_true.shape)\n","  t1 = top_k_accuracy_score(y_true, y_pred,k=1, labels = list(range(21,31)), normalize=True)\n","  t3 = top_k_accuracy_score(y_true, y_pred,k=3, labels = list(range(21,31)), normalize=True)\n","  t5 = top_k_accuracy_score(y_true, y_pred,k=5, labels = list(range(21,31)), normalize=True)\n","  print('top 1 accuracy is',t1)\n","  print('top 3 accuracy is', t3)\n","  print('top 5 accuracy is', t5)\n","  # print(y_pred)\n","  # print(y_true)\n","\n","eval_emb()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ndy1dYb-vfev","executionInfo":{"status":"ok","timestamp":1668708641796,"user_tz":-330,"elapsed":521,"user":{"displayName":"Nihal Rao","userId":"16198834853640975474"}},"outputId":"51f67c1a-4440-4578-8640-61dfde9da048"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["top 1 accuracy is 0.3418803418803419\n","top 3 accuracy is 0.49572649572649574\n","top 5 accuracy is 0.6239316239316239\n"]}]}]}